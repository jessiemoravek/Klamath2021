---
title: "2021_Wavelets"
output:
  word_document: default
  html_document: default
---

```{r, include=F}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(patchwork)
library(astsa)
library(forecast)
library(dplyr)
library(pander)
library(MARSS)
library(MASS)
library(gridExtra)
library(weathermetrics)
library(ggplot2)
library(zoo)
library(imputeTS) 
library(WaveletComp)

```
#ALEXANDER
#Read in Data
```{r}
##Reading in a 10 year hourly temperature time series dataset from Alexander Pond called "APH" (Alexander Pond Historical)
APH <- read.csv("Alexander_Historical_2.csv")
APH$date <- lubridate::mdy_hm(APH$Date_Time) #convert dates to POSIXct format and bin by hour

#Check for missing data
missing_data <- APH[!complete.cases(APH),] 
missing_data 
#Wavelets require a complete dataset with no missing data. Since there is missing data in this dataset, we will need to interpolate

#Bin data by hour
APH$hour <- lubridate::round_date(APH$date, unit="hour") #Before we interpolate, let's bin by hour
head(APH) #check the dataset start date, use for "hour" sequence
tail(APH) #check the dataset end date, use for "hour" sequence

#Create hourly sequence to ensure all missing data is accounted for
hour <- seq(mdy_h('12/16/2010 13'),mdy_h('11/24/2021 14'),by = "hour") #Create an object that goes hour by hour for the entire time series to ensure that ALL missing data is accounted for
hour <- as.data.frame(hour) #convert "hour" to data frame
APH <- left_join(hour, APH) #left join hour and dataset
missing_data <- APH[!complete.cases(APH),] 
missing_data #Now we are sure that all the missing hour time steps are included.

#z score to control for outliers
APH$zTemp <- zscore(APH$Temp)

#Convert to time series
APH_ts <- ts(APH$zTemp, start = c(351, 13), frequency = 24) # This time series starts on 16 Dec 2010 at~13:00, so it starts on day 351 at hour 13 and the frequency is 24 (24 hours per day)
#^^^This is very confusing and I still don't fully understand how to convert data to time series so may want to ask Albert for clarification. 
ts.plot(APH_ts,main="Temperature",ylab = "Temperature (C)", xlab = "Time")
```

#Interpolate missing data
```{r, cache = TRUE}
#Run ARIMA to interpolate missing data
y <- APH_ts
date_s <- APH$hour
y_na <- ifelse(is.na(y),0,NA)

fit <- auto.arima(y,trace=TRUE) #fit limited number of models (faster)
summary(fit) #Take a closer look at the best fitted model
forecast_fit <- forecast(y,model=fit) #Predict values using the calibration dataset

```

#Plot interpolated data
```{r}
#Plot the observed and interpolated temperature regimes
par(mar=c(2,4,1,1)) 
plot(date_s,y,xlab="Time",ylab="Temp",lwd=2,type="l") 
lines(date_s,forecast_fit$fitted,col="steelblue")

#Plot predicted versus observed values
scatter.smooth(y,forecast_fit$fitted,xlab="Observed",ylab="Predicted",pch=".",main = "Temperature")
abline(0,1,lty=2)
R2 = round(cor.test(y,forecast_fit$fitted,na.rm=T)$estimate^2,2)
mtext(side=3,line=-2,adj=0.1,bquote(R^2 == .(R2)))
```

#Check residuals of interpolated data
```{r}
#Check residuals of the interpolation process
checkresiduals(fit) #also gives the results for the Ljung_Box test with H0 = randomly distributed errors (white noise)

#plot residuals versus fitted values (=check for heterosedasticity); if problems try to transform the data 
par(mar=c(4,4,4,4))
scatter.smooth(forecast_fit$fitted,forecast_fit$residuals,pch = ".",ylab="Residuals",xlab="Fitted values")
```

#Smooth interpolated data
##NOTE: This chunk takes FOREVER beware
```{r, cache = TRUE}
#Interpolate missing values using a Kalman filter (=smoother)
y_inter <- na_kalman(y,model=fit$model) #use the fitted model
#Plot the results
par(mar=c(2,4,1,1))
plot(y_inter,xlab="",ylab="Temperature (C)",col="steelblue",main="Interpolation missing values")
lines(y,col="black")

#save  output as an rds
saveRDS(y_inter, "y_inter_Alexander.rds")

#read in your data 
y_inter <- readRDS("y_inter_Alexander.rds")
```

#Format interpolated time series into a dataframe
```{r}
#Put the interpolated temperature dataset (y_inter) into a dataset with the correct dates (this does not work using the time series object because I had to designate hourly steps when making the time series, so the dates are messed up. There is probably a better way to do this...). 
x <- as.data.frame(y_inter) #change y_inter from a ts to a dataframe
x$ID <- seq.int(nrow(x)) #add a unique ID, check it is correct length
date <- as.data.frame(APH$hour) #make the unique "hour" index from APH into a separate dataframe
date$ID <- seq.int(nrow(date)) #give that a unique ID that aligns with x
y_inter_df <- merge(x,date,"ID") #merge the two dataframes
colnames(y_inter_df)<-c("ID","temp","date") #rename columns
```

#Wavelet
```{r}
#run the wavelet
my.w <- analyze.wavelet(y_inter_df, "temp",
                        loess.span = 0,
                        dt = 1/24, # this is the time resolution, here 24 samples per day
                        make.pval = TRUE, n.sim = 10,# number of simulations, should be much higher for a paper
                        date.format = "%Y-%m-%d-%h") 
str(my.w) # Output
```

#Wavelet Image
```{r}
wt.image(my.w, color.key = "quantile", n.levels = 250, main = "Alexander Pond Wavelet",  
         legend.params = list(lab = "wavelet power levels", mar = 6.5, lab.line=4, label.digits = 4), label.time.axis=TRUE,show.date=TRUE,
         periodlab = "period (days)")
```

#Pull a specific period (i.e. see wavelet frequencies at a specific period, such as 24 hr or 365 days)
```{r}
my.w$Period # We will be targeting row #71 (period ~ hourly)
plot.ts(my.w$Power[71,])
```

#STENDER
#Read in Data
```{r}
##Reading in a 10 year hourly temperature time series dataset from Alexander Pond called "APH" (Alexander Pond Historical)
SPH <- read.csv("Stender_Historical_2.csv")
SPH$date <- lubridate::mdy_hm(SPH$Date_Time) #convert dates to POSIXct format and bin by hour

#Check for missing data
missing_data <- SPH[!complete.cases(SPH),] 
missing_data 
#Wavelets require a complete dataset with no missing data. Since there is missing data in this dataset, we will need to interpolate

#Bin data by hour
SPH$hour <- lubridate::round_date(SPH$date, unit="hour") #Before we interpolate, let's bin by hour
head(SPH) #check the dataset start date, use for "hour" sequence
tail(SPH) #check the dataset end date, use for "hour" sequence

#Create hourly sequence to ensure all missing data is accounted for
hour <- seq(mdy_h('12/16/2010 13'),mdy_h('11/24/2021 14'),by = "hour") #Create an object that goes hour by hour for the entire time series to ensure that ALL missing data is accounted for
hour <- as.data.frame(hour) #convert "hour" to data frame
SPH <- left_join(hour, SPH) #left join hour and dataset
missing_data <- SPH[!complete.cases(SPH),] 
missing_data #Now we are sure that all the missing hour time steps are included.

#z score to control for outliers
SPH$zTemp <- zscore(SPH$Temp)

#Convert to time series
SPH_ts <- ts(SPH$zTemp, start = c(351, 13), frequency = 24) # This time series starts on 16 Dec 2010 at~13:00, so it starts on day 351 at hour 13 and the frequency is 24 (24 hours per day)
#^^^This is very confusing and I still don't fully understand how to convert data to time series so may want to ask Albert for clarification. 
ts.plot(SPH_ts,main="Temperature",ylab = "Temperature (C)", xlab = "Time")
```

#Interpolate missing data
```{r, cache = TRUE}
#Run ARIMA to interpolate missing data
y2 <- SPH_ts
date_s2 <- SPH$hour
y_na2 <- ifelse(is.na(y2),0,NA)

fit2 <- auto.arima(y2,trace=TRUE) #fit limited number of models (faster)
summary(fit2) #Take a closer look at the best fitted model
forecast_fit2 <- forecast(y2,model=fit2) #Predict values using the calibration dataset

```

#Plot interpolated data
```{r}
#Plot the observed and interpolated temperature regimes
par(mar=c(2,4,1,1)) 
plot(date_s2,y2,xlab="Time",ylab="Temp",lwd=2,type="l") 
lines(date_s2,forecast_fit2$fitted,col="steelblue")

#Plot predicted versus observed values
scatter.smooth(y2,forecast_fit2$fitted,xlab="Observed",ylab="Predicted",pch=".",main = "Temperature")
abline(0,1,lty=2)
R2 = round(cor.test(y2,forecast_fit2$fitted,na.rm=T)$estimate^2,2)
mtext(side=3,line=-2,adj=0.1,bquote(R^2 == .(R2)))
```

#Check residuals of interpolated data
```{r}
#Check residuals of the interpolation process
checkresiduals(fit2) #also gives the results for the Ljung_Box test with H0 = randomly distributed errors (white noise)

#plot residuals versus fitted values (=check for heterosedasticity); if problems try to transform the data 
par(mar=c(4,4,4,4))
scatter.smooth(forecast_fit2$fitted,forecast_fit2$residuals,pch = ".",ylab="Residuals",xlab="Fitted values")
```

#Smooth interpolated data
##NOTE: This chunk takes FOREVER beware
```{r, cache = TRUE}
#Interpolate missing values using a Kalman filter (=smoother)
y_inter2 <- na_kalman(y2,model=fit2$model) #use the fitted model
#Plot the results
par(mar=c(2,4,1,1))
plot(y_inter2,xlab="",ylab="Temperature (C)",col="steelblue",main="Interpolation missing values")
lines(y2,col="black")

#save  output as an rds
saveRDS(y_inter2, "y_inter_Stender.rds")

#read in your data 
y_inter2 <- readRDS("y_inter_Stender.rds")
```

#Format interpolated time series into a dataframe
```{r}
#Put the interpolated temperature dataset (y_inter) into a dataset with the correct dates (this does not work using the time series object because I had to designate hourly steps when making the time series, so the dates are messed up. There is probably a better way to do this...). 
x2 <- as.data.frame(y_inter2) #change y_inter from a ts to a dataframe
x2$ID <- seq.int(nrow(x2)) #add a unique ID, check it is correct length
date2 <- as.data.frame(SPH$hour) #make the unique "hour" index from APH into a separate dataframe
date2$ID <- seq.int(nrow(date2)) #give that a unique ID that aligns with x
y_inter2_df <- merge(x2,date2,"ID") #merge the two dataframes
colnames(y_inter2_df)<-c("ID","temp","date") #rename columns
```

#Wavelet
```{r}
#run the wavelet
my.w2 <- analyze.wavelet(y_inter2_df, "temp",
                        loess.span = 0,
                        dt = 1/24, # this is the time resolution, here 24 samples per day
                        make.pval = TRUE, n.sim = 10,# number of simulations, should be much higher for a paper
                        date.format = "%Y-%m-%d-%h") 
str(my.w2) # Output
```

#Wavelet Image
```{r}
wt.image(my.w2, color.key = "quantile", n.levels = 250, main = "Stender Pond Wavelet",  
         legend.params = list(lab = "wavelet power levels", mar = 6.5, lab.line=4, label.digits = 4), label.time.axis=TRUE,show.date=TRUE,
         periodlab = "period (days)")
```

#Pull a specific period (i.e. see wavelet frequencies at a specific period, such as 24 hr or 365 days)
```{r}
my.w2$Period # We will be targeting row #71 (period ~ hourly)
plot.ts(my.w2$Power[71,])
```

