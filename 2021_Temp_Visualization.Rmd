---
title: "2021_Temp_Visualization"
output: html_document
---

Standing questions for Albert:
-Stender Pond SN 20878650 is for some reason reading on offset 15 min intervals (i.e. starting on 16:37?) How should I deal with this? 
-If I can tell a sensor was out of the water, do I remove those datapoints? 
-How do I deal with datasets that are missing several months of data? 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(patchwork)
library(astsa)
library(forecast)
library(dplyr)
library(pander)
library(MARSS)
library(MASS)
library(gridExtra)
library(weathermetrics)
```

##Variates and responses ("dat")

### Cleaning datasets, and aligning dates
#### Alexander Pond 
```{r, include=FALSE}
AP1 <- read.csv("Alexander_SN_20870137.csv")
AP1$date <- lubridate::mdy_hm(AP1$Date_Time)
plot(AP1$date, AP1$Temp)
plot(AP1$date, AP1$Intensity)#Note: Something wrong with intensity values starting in April??
head(AP1, n = 50) #Need to remove first 4 values (not in the water yet)
tail(AP1, n = 100) #Need to remove last 8 values. Sensor was dying and repeated a measurement at 11:00, removed at 10:45 to be safe. 
AP1 <- AP1[c(4:30126),] 
str(AP1) #Now we have 30123 observations
missing_data <- AP1[!complete.cases(AP1),] #Missing data at 10:37 on 28 July 2020 when sensor was read. Deleted these in .csv file
missing_data

#Position dataset into a full year data frame by daily steps
AP1$day <- lubridate::floor_date(AP1$date, unit="day") #Bin by day
head(AP1, n=70) #check the dataset start date
tail(AP1) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
AP1 <- left_join(day, AP1) #join day and dataset
str(AP1)

#Group by day and calculate mean, max, min, amp
AP1_daily <- AP1 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = FALSE}
AP2 <- read.csv("Alexander_SN_20878648.csv")
AP2$date <- lubridate::mdy_hm(AP2$Date_Time)
plot(AP2$date, AP2$Temp)
head(AP2, n = 50) #Need to remove first 6 values (not in the water yet)
tail(AP2, n = 50) #Last NAs already removed in .csv file. Note that sensor failed on 1 October 2020
AP2 <- AP2[c(7:7976),] 
str(AP2) #Now we have 7970  observations
missing_data <- AP2[!complete.cases(AP2),] 
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
AP2$day <- lubridate::floor_date(AP2$date, unit="day") #Bin by day
head(AP2, n=70) #check the dataset start date
tail(AP2) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
AP2 <- left_join(day, AP2) #join day and dataset
str(AP2)

#Group by day and calculate mean, max, min, amp
AP2_daily <- AP2 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = FALSE}
AP3 <- read.csv("Alexander_SN_20878664.csv")
AP3$date <- lubridate::mdy_hm(AP3$Date_Time)
plot(AP3$date, AP3$Temp)
head(AP3, n = 50) #Need to remove first 5 values (not in the water yet)
tail(AP3, n = 50) #Last NAs already removed in .csv file. 
AP3 <- AP3[c(6:35309),] 
str(AP3) #Now we have 35304  observations
missing_data <- AP3[!complete.cases(AP3),] 
missing_data#No missing data

#Position dataset into a full year data frame by daily steps
AP3$day <- lubridate::floor_date(AP3$date, unit="day") #Bin by day
head(AP3, n=70) #check the dataset start date
tail(AP3) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
AP3 <- left_join(day, AP3) #join day and dataset
str(AP3)

#Group by day and calculate mean, max, min, amp
AP3_daily <- AP3 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = FALSE}
APck <- read.csv("AlexanderCk_SN_20878703.csv")
APck$date <- lubridate::mdy_hm(APck$Date_Time)
plot(APck$date, APck$Temp)
head(APck, n = 100) #Need to remove first 87 values (not in the water yet)
tail(APck, n = 500) #Last NAs already removed in .csv file. Sensor seems like it might be out of the water somewhere in late Jan 2021
APck[c(18000:18500),] 
APck <- APck[c(88:18125),] #Need to cut off everything after 17 January 2021 becuase sensor out of water which we can see from amplitude
str(APck) #Now we have 18038  observations
missing_data <- APck[!complete.cases(APck),] 
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
APck$day <- lubridate::floor_date(APck$date, unit="day") #Bin by day
head(APck, n=70) #check the dataset start date
tail(APck) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
APck <- left_join(day, APck) #join day and dataset
head(APck_daily,300)
#2021-02-23	

#Group by day and calculate mean, max, min, amp
APck_daily <- APck %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))
plot(APck_daily$day,APck_daily$amp_temp)

```


#####Stender Pond
```{r, include = FALSE}
SP1 <- read.csv("Stender_SN_20870127.csv")
SP1$date <- lubridate::mdy_hm(SP1$Date_Time)
plot(SP1$date, SP1$Temp)
head(SP1, n = 100) #Need to remove first 11 values (not in the water yet) 
tail(SP1) #Last NAs already removed in .csv file.
SP1 <- SP1[c(12:35241),] 
str(SP1) #Now we have 35230  observations
missing_data <- SP1[!complete.cases(SP1),] 
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
SP1$day <- lubridate::floor_date(SP1$date, unit="day") #Bin by day
head(SP1, n=70) #check the dataset start date
tail(SP1) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
SP1 <- left_join(day, SP1) #join day and dataset
str(SP1)

#Group by day and calculate mean, max, min, amp
SP1_daily <- SP1 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


```{r, include = FALSE}
SPout <- read.csv("StenderOut_SN_20878705.csv")
SPout$date <- lubridate::mdy_hm(SPout$Date_Time)
plot(SPout$date, SPout$Temp)
head(SPout, n = 100) #Need to remove first 10 values (never in the water, in a dry outflow channel)
tail(SPout) #Last NAs already removed in .csv file.
SPout <- SPout[c(11:35240),] 
str(SPout) #Now we have 35230  observations
missing_data <- SPout[!complete.cases(SPout),] 
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
SPout$day <- lubridate::floor_date(SPout$date, unit="day") #Bin by day
head(SPout, n=70) #check the dataset start date
tail(SPout) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
SPout <- left_join(day, SPout) #join day and dataset
str(SPout)

#Group by day and calculate mean, max, min, amp
SPout_daily <- SPout %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


```{r, include = FALSE}
#SN 650 (11 - 28 July 2020)
SP2a <- read.csv("StenderRm_SN_20878650.csv")
SP2a$date <- lubridate::mdy_hm(SP2a$Date_Time)
plot(SP2a$date, SP2a$Temp)
head(SP2a, n = 100) #Need to remove first 8 values
tail(SP2a, n = 800) #Need to remove NAs in the last several days and get up to 12:30 when next sensor was placed. Lots of weird NAs to remove
SP2a <- SP2a[c(9:1625,1661:1662),] 
str(SP2a) #Now we have 1619 observations
missing_data <- SP2a[!complete.cases(SP2a),]
missing_data #No missing data
```


```{r, include = FALSE}
#SN 711 (28 July 2020 - 13 July 2021)
SP2b <- read.csv("Stender_SN_20878711.csv")
SP2b$date <- lubridate::mdy_hm(SP2b$Date_Time)
plot(SP2b$date, SP2b$Temp)
head(SP2b, n = 100) #Need to remove first value to match with SN 650
tail(SP2b, n = 800) #Last NAs already removed in .csv file.
SP2b <- SP2b[c(2:33614),] 
str(SP2b) #Now we have 33613 observations
missing_data <- SP2b[!complete.cases(SP2b),] 
missing_data #No missing data
```


```{r, include = FALSE}
##Combine SN 650 and SN 711 (711 replaced 650 on 28 July 2020 at ~12:15)
#SP2 is 11 July 2020 - 13 July 2021

SP2 <- rbind(SP2a,SP2b)
plot(SP2$date,SP2$Temp)
str(SP2) #Now we have 35232  observations
missing_data <- SP2[!complete.cases(SP2),] 
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
SP2$day <- lubridate::floor_date(SP2$date, unit="day") #Bin by day
head(SP2, n=70) #check the dataset start date
tail(SP2) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
SP2 <- left_join(day, SP2) #join day and dataset
str(SP2)

#Group by day and calculate mean, max, min, amp
SP2_daily <- SP2 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


```{r, include = FALSE}
SPck <- read.csv("StenderCk_SN_20870136.csv")
SPck$date <- lubridate::mdy_hm(SPck$Date_Time)
plot(SPck$date, SPck$Temp)
head(SPck, n = 100) #Need to remove first 5 values. Also remove 1140:1141 on 28 July 2020 when sensor was reset 
tail(SPck, n = 800) #Sensor started to fail on 15 April 2021, removed last day of readings. Note that sensor failed on 16 April 2021
SPck <- SPck[c(6:1139,1142:26240),] 
str(SPck) #Now we have 26233 observations
missing_data <- SPck[!complete.cases(SPck),] #No missing data
missing_data

#Position dataset into a full year data frame by daily steps
SPck$day <- lubridate::floor_date(SPck$date, unit="day") #Bin by day
head(SPck, n=70) #check the dataset start date
tail(SPck) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
SPck <- left_join(day, SPck) #join day and dataset
str(SPck)

#Group by day and calculate mean, max, min, amp
SPck_daily <- SPck %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

#####Durazo Pond
```{r, include = FALSE}
Durazo <- read.csv("Durazo_SN_20878643.csv")
Durazo$date <- lubridate::mdy_hm(Durazo$Date_Time)
plot(Durazo$date, Durazo$Temp)
head(Durazo, n = 100) #Need to remove first 9 values 
tail(Durazo) #NAs removed in excel
Durazo <- Durazo[c(10:35019),] 
str(Durazo) #Now we have 35010  observations
missing_data <- Durazo[!complete.cases(Durazo),] 
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
Durazo$day <- lubridate::floor_date(Durazo$date, unit="day") #Bin by day
head(Durazo, n=70) #check the dataset start date
tail(Durazo) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
Durazo <- left_join(day, Durazo) #join day and dataset
str(Durazo)

#Group by day and calculate mean, max, min, amp
Durazo_daily <- Durazo %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))


```


#####Lower Seiad Pond
```{r, include = FALSE}
LS <- read.csv("LowerSeiad_SN_20878706.csv")
LS$date <- lubridate::mdy_hm(LS$Date_Time)
plot(LS$date, LS$Temp)
head(LS, n = 100) #Need to remove first 3 values 
tail(LS) #Last several NAs removed in excel 
LS <- LS[c(4:35021),] 
str(LS) #Now we have 35018 observations
missing_data <- LS[!complete.cases(LS),] 
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
LS$day <- lubridate::floor_date(LS$date, unit="day") #Bin by day
head(LS, n=70) #check the dataset start date
tail(LS) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
LS <- left_join(day, LS) #join day and dataset
str(LS)

#Group by day and calculate mean, max, min, amp
LS_daily <- LS %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = FALSE}
LSck <- read.csv("LowerSeiadCk_SN_20878668.csv")
LSck$date <- lubridate::mdy_hm(LSck$Date_Time)
plot(LSck$date, LSck$Temp)
head(LSck, n = 100) #Need to remove first 4 values 
tail(LSck) #Need to remove last value
LSck <- LSck[c(5:35020),] 
str(LSck) #Now we have 35016  observations
missing_data <- LSck[!complete.cases(LSck),] #No missing data
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
LSck$day <- lubridate::floor_date(LSck$date, unit="day") #Bin by day
head(LSck, n=70) #check the dataset start date
tail(LSck) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
LSck <- left_join(day, LSck) #join day and dataset
str(LSck)

#Group by day and calculate mean, max, min, amp
LSck_daily <- LSck %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

#####May Pond
```{r, include = FALSE}
May <- read.csv("May_SN_20870134.csv")
May$date <- lubridate::mdy_hm(May$Date_Time)
plot(May$date, May$Temp)
head(May, n = 100) #Need to remove first 3 values 
tail(May, n = 400) #NAs removed in .csv file -- Note, sensor died in June and removed last several days of data 
May <- May[c(4:1438,1443:32628),] 
str(May) #Now we have 32621 observations
missing_data <- May[!complete.cases(May),] #No missing data
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
May$day <- lubridate::floor_date(May$date, unit="day") #Bin by day
head(May, n=70) #check the dataset start date
tail(May) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
May <- left_join(day, May) #join day and dataset
str(May)

#Group by day and calculate mean, max, min, amp
May_daily <- May %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = FALSE}
MayCk <- read.csv("MayCk_SN_20878646.csv")
MayCk$date <- lubridate::mdy_hm(MayCk$Date_Time)
plot(MayCk$date, MayCk$Temp)
head(MayCk, n = 100) #Need to remove first 3 values 
tail(MayCk) #All good
MayCk <- MayCk[c(4:35028),] 
str(MayCk) #Now we have 35025  observations
missing_data <- MayCk[!complete.cases(MayCk),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
MayCk$day <- lubridate::floor_date(MayCk$date, unit="day") #Bin by day
head(MayCk, n=70) #check the dataset start date
tail(MayCk) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
MayCk <- left_join(day, MayCk) #join day and dataset
str(MayCk)

#Group by day and calculate mean, max, min, amp
MayCk_daily <- MayCk %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

####Fish Gulch
```{r, include = F}
FG2 <- read.csv("FishGulch_SN_20870133.csv")
FG2$date <- lubridate::mdy_hm(FG2$Date_Time) 
plot(FG2$date, FG2$Temp)
head(FG2, n = 50) #Need to remove first 10 values (not in the water yet)
tail(FG2, n = 50) #Look sok 
FG2 <- FG2[c(11:1653,1657:35244),] 
str(FG2) #Now we have 35231 observations
missing_data <- FG2[!complete.cases(FG2),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
FG2$day <- lubridate::floor_date(FG2$date, unit="day") #Bin by day
head(FG2, n=70) #check the dataset start date
tail(FG2) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
FG2 <- left_join(day, FG2) #join day and dataset
str(FG2)

#Group by day and calculate mean, max, min, amp
FG2_daily <- FG2 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


```{r,include = F}
FG3 <- read.csv("FishGulch_SN_20878708.csv")
FG3$date <- lubridate::mdy_hm(FG3$Date_Time) 
plot(FG3$date, FG3$Temp)
head(FG3, n = 50) #Need to remove first 8 values (not in the water yet)
tail(FG3, n = 50) #Looks ok. 
FG3 <- FG3[c(9:1652,1666:35242),] 
str(FG3) #Now we have 35234  observations
missing_data <- FG3[!complete.cases(FG3),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
FG3$day <- lubridate::floor_date(FG3$date, unit="day") #Bin by day
head(FG3, n=70) #check the dataset start date
tail(FG3) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
FG3 <- left_join(day, FG3) #join day and dataset
str(FG3)

#Group by day and calculate mean, max, min, amp
FG3_daily <- FG3 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


```{r, include = F}
FGck <- read.csv("FishGulchCk_SN_20878671.csv")
FGck$date <- lubridate::mdy_hm(FGck$Date_Time) 
plot(FGck$date, FGck$Temp)
head(FGck, n = 50) #looks ok
tail(FGck, n = 50) #looks ok
FGck <- FGck[c(1:1640,1643:35233),] 
str(FGck) #Now we have 35231 observations
missing_data <- FGck[!complete.cases(FGck),] 
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
FGck$day <- lubridate::floor_date(FGck$date, unit="day") #Bin by day
head(FGck, n=70) #check the dataset start date
tail(FGck) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
FGck <- left_join(day, FGck) #join day and dataset
str(FGck)

#Group by day and calculate mean, max, min, amp
FGck_daily <- FGck %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


#####Goodman Pond
```{r, include = F}
GP1 <- read.csv("Goodman_SN_20878644.csv")
GP1$date <- lubridate::mdy_hm(GP1$Date_Time)
plot(GP1$date, GP1$Temp)
head(GP1, n = 50) #Need to remove first 1 values (not in the water yet)
tail(GP1, n = 50) #Need to remove last 8 values (out of water) 
GP1 <- GP1[c(2:1749,1753:35336),] 
str(GP1) #Now we have 35335  observations
missing_data <- GP1[!complete.cases(GP1),] #No missing data
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
GP1$day <- lubridate::floor_date(GP1$date, unit="day") #Bin by day
head(GP1, n=70) #check the dataset start date
tail(GP1) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
GP1 <- left_join(day, GP1) #join day and dataset
str(GP1)

#Group by day and calculate mean, max, min, amp
GP1_daily <- GP1 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


```{r, include = F}
GP2 <- read.csv("Goodman_SN_20878647.csv")
GP2$date <- lubridate::mdy_hm(GP2$Date_Time)
plot(GP2$date, GP2$Temp)
head(GP2, n = 50) #Need to remove first 2 values (not in the water yet)
tail(GP2, n = 50) #looks ok 
GP2 <- GP2[c(3:1749,1752:35343),] 
str(GP2) #Now we have 35341  observations
missing_data <- GP2[!complete.cases(GP2),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
GP2$day <- lubridate::floor_date(GP2$date, unit="day") #Bin by day
head(GP2, n=70) #check the dataset start date
tail(GP2) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
GP2 <- left_join(day, GP2) #join day and dataset
str(GP2)

#Group by day and calculate mean, max, min, amp
GP2_daily <- GP2 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


```{r, include = F}
GP3 <- read.csv("Goodman_SN_20878659.csv")
GP3$date <- lubridate::mdy_hm(GP3$Date_Time)
plot(GP3$date, GP3$Temp)
head(GP3, n = 50) #Need to remove first 2 values (not in the water yet)
tail(GP3, n = 50) #looks ok 
GP3 <- GP3[c(3:1748,1751:35343),] 
str(GP3) #Now we have 35339  observations
missing_data <- GP3[!complete.cases(GP3),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
GP3$day <- lubridate::floor_date(GP3$date, unit="day") #Bin by day
head(GP3, n=70) #check the dataset start date
tail(GP3) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
GP3 <- left_join(day, GP3) #join day and dataset
str(GP3)

#Group by day and calculate mean, max, min, amp
GP3_daily <- GP3 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = F}
GPck <- read.csv("GoodmanCk_SN_20878654.csv")
GPck$date <- lubridate::mdy_hm(GPck$Date_Time)
plot(GPck$date, GPck$Temp)
head(GPck, n = 50) #Need to remove first 1 values (not in the water yet)
tail(GPck, n = 50) #Need to remove last 1 value 
GPck <- GPck[c(2:1071,1074:34666),] 
str(GPck) #Now we have 34663  observations
missing_data <- GPck[!complete.cases(GPck),]#No missing data
missing_data

#Position dataset into a full year data frame by daily steps
GPck$day <- lubridate::floor_date(GPck$date, unit="day") #Bin by day
head(GPck, n=70) #check the dataset start date
tail(GPck) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
GPck <- left_join(day, GPck) #join day and dataset
str(GPck)

#Group by day and calculate mean, max, min, amp
GPck_daily <- GPck %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


#####Upper Lawrence Pond
```{r, include = F}
ULout <- read.csv("UpperLawrence3_SN_20878673.csv")
ULout$date <- lubridate::mdy_hm(ULout$Date_Time)
plot(ULout$date, ULout$Temp)
head(ULout, n = 50) #Need to remove first 22 values (not in the water yet)
tail(ULout, n = 50) #looks ok 
ULout <- ULout[c(23:1943,1946:35520),] 
str(ULout) #Now we have 1922 observations
missing_data <- ULout[!complete.cases(ULout),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
ULout$day <- lubridate::floor_date(ULout$date, unit="day") #Bin by day
head(ULout, n=70) #check the dataset start date
tail(ULout) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
ULout <- left_join(day, ULout) #join day and dataset
str(ULout)

#Group by day and calculate mean, max, min, amp
ULout_daily <- ULout %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = F}
UL1 <- read.csv("UpperLawrence1_SN_20878682.csv")
UL1$date <- lubridate::mdy_hm(UL1$Date_Time)
plot(UL1$date, UL1$Temp)
head(UL1, n = 50) #Need to remove first 5 values (not in the water yet)
tail(UL1, n = 1150) #Need to remove last several days; sensor removed on 12 July 2021
UL1 <- UL1[c(6:35531),] 
str(UL1) #Now we have 35526  observations
missing_data <- UL1[!complete.cases(UL1),] #No missing data
missing_data

#Position dataset into a full year data frame by daily steps
UL1$day <- lubridate::floor_date(UL1$date, unit="day") #Bin by day
head(UL1, n=70) #check the dataset start date
tail(UL1) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
UL1 <- left_join(day, UL1) #join day and dataset
str(UL1)

#Group by day and calculate mean, max, min, amp
UL1_daily <- UL1 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

time / 0.25
```{r, include = F}
UL3 <- read.csv("UpperLawrence3_SN_20878663.csv")
UL3$date <- lubridate::mdy_hm(UL3$Date_Time)
plot(UL3$date, UL3$Temp)
head(UL3, n = 50) #Need to remove first 19 values (not in the water yet)
tail(UL3, n = 50) #looks ok 
UL3 <- UL3[c(20:1943,1947:35513),] 
str(UL3) #Now we have 35491 observations
missing_data <- UL3[!complete.cases(UL3),] #No missing data
missing_data

#Position dataset into a full year data frame by daily steps
UL3$day <- lubridate::floor_date(UL3$date, unit="day") #Bin by day
head(UL3, n=70) #check the dataset start date
tail(UL3) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
UL3 <- left_join(day, UL3) #join day and dataset
str(UL3)

#Group by day and calculate mean, max, min, amp
UL3_daily <- UL3 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = F}
ULck <- read.csv("LowerLawrenceCk_SN_20870140.csv") #Lower and Upper Lawrence have the same sensor in horse creek. In 2020 i labeled that ULck, but the file name for 2021 is Lower Lawrence creek (same sensor)
ULck$date <- lubridate::mdy_hm(ULck$Date_Time)
plot(ULck$date, ULck$Temp)
head(ULck, n = 50) #Need to remove first 28 values (not in the water yet)
tail(ULck, n = 50) #looks ok 
ULck <- ULck[c(29:1945,1948:35526),] 
str(ULck) #Now we have 35496  observations
missing_data <- ULck[!complete.cases(ULck),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
ULck$day <- lubridate::floor_date(ULck$date, unit="day") #Bin by day
head(ULck, n=70) #check the dataset start date
tail(ULck) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
ULck <- left_join(day, ULck) #join day and dataset
str(ULck)

#Group by day and calculate mean, max, min, amp
ULck_daily <- ULck %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


#####Lower Lawrence Pond
```{r, include = F}
LL1 <- read.csv("LowerLawrence_SN_20870131.csv")
LL1$date <- lubridate::mdy_hm(LL1$Date_Time)
plot(LL1$date, LL1$Temp)
head(LL1, n = 50) #Need to remove first 9 values (not in the water yet)
tail(LL1, n = 50) #looks ok
LL1 <- LL1[c(10:1737,1740:35317),] 
str(LL1) #Now we have 1728 observations
missing_data <- LL1[!complete.cases(LL1),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
LL1$day <- lubridate::floor_date(LL1$date, unit="day") #Bin by day
head(LL1, n=70) #check the dataset start date
tail(LL1) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
LL1 <- left_join(day, LL1) #join day and dataset
str(LL1)

#Group by day and calculate mean, max, min, amp
LL1_daily <- LL1 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```


```{r, include = F}
LL2 <- read.csv("LowerLawrence_SN_20878651.csv")
LL2$date <- lubridate::mdy_hm(LL2$Date_Time)
plot(LL2$date, LL2$Temp)
head(LL2, n = 50) #Need to remove first 7 values (not in the water yet)
tail(LL2, n = 50) #looks ok
LL2 <- LL2[c(8:1737,1740:35277),] 
str(LL2) 
missing_data <- LL2[!complete.cases(LL2),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
LL2$day <- lubridate::floor_date(LL2$date, unit="day") #Bin by day
head(LL2, n=70) #check the dataset start date
tail(LL2) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
LL2 <- left_join(day, LL2) #join day and dataset
str(LL2)

#Group by day and calculate mean, max, min, amp
LL2_daily <- LL2 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))

```

```{r, include = F}
LL3 <- read.csv("LowerLawrence_SN_20878670.csv")
LL3$date <- lubridate::mdy_hm(LL3$Date_Time)
plot(LL3$date, LL3$Temp)
head(LL3, n = 50) #Need to remove first 6 values (not in the water yet)
tail(LL3, n = 50) #looks ok 
LL3 <- LL3[c(7:1737,1740:35316),] 
str(LL3) 
missing_data <- LL3[!complete.cases(LL3),]
missing_data #No missing data

#Position dataset into a full year data frame by daily steps
LL3$day <- lubridate::floor_date(LL3$date, unit="day") #Bin by day
head(LL3, n=70) #check the dataset start date
tail(LL3) #check the dataset end date
day <- seq(mdy('7/1/2020'),mdy('7/13/2021'),by = "day") #Create an object that goes day by day for whole series
day <- as.data.frame(day) #convert "day" to data frame
str(day) #check that it's a data frame
LL3 <- left_join(day, LL3) #join day and dataset
str(LL3)

#Group by day and calculate mean, max, min, amp
LL3_daily <- LL3 %>% 
  group_by(day) %>% 
  summarize(mean_temp=mean(Temp),max_temp=max(Temp), min_temp=min(Temp), amp_temp=(max(Temp)-min(Temp)))


```

##Data Matrix Mean Temp
Recall: rows are states, columns are time steps. 
```{r, include = F}
#Daily temperature averages (mean)
matrix7 <- matrix(nrow=26,ncol=378)
matrix7[1,] <- AP1_daily$mean_temp
matrix7[2,] <- AP2_daily$mean_temp
matrix7[3,] <- AP3_daily$mean_temp
matrix7[4,] <- APck_daily$mean_temp
matrix7[5,] <- SP1_daily$mean_temp
matrix7[6,] <- SP2_daily$mean_temp
matrix7[7,] <- SPck_daily$mean_temp
matrix7[8,] <- Durazo_daily$mean_temp
matrix7[9,] <- LS_daily$mean_temp
matrix7[10,] <- LSck_daily$mean_temp
matrix7[11,] <- May_daily$mean_temp
matrix7[12,] <- MayCk_daily$mean_temp
matrix7[13,] <- FG2_daily$mean_temp
matrix7[14,] <- FG3_daily$mean_temp
matrix7[15,] <- FGck_daily$mean_temp
matrix7[16,] <- GP1_daily$mean_temp
matrix7[17,] <- GP2_daily$mean_temp
matrix7[18,] <- GP3_daily$mean_temp
matrix7[19,] <- GPck_daily$mean_temp
matrix7[20,] <- ULout_daily$mean_temp
matrix7[21,] <- UL1_daily$mean_temp
matrix7[22,] <- UL3_daily$mean_temp
matrix7[23,] <- ULck_daily$mean_temp
matrix7[24,] <- LL1_daily$mean_temp
matrix7[25,] <- LL2_daily$mean_temp
matrix7[26,] <- LL3_daily$mean_temp

#log transform and de-mean the data
dat_mean <- matrix7
dat_mean <- log(dat_mean)
transformed_dat <- zscore(dat_mean)
```

##Z-Matrices
```{r }
#Hypothesis 1: All ponds and creeks are separate
matrix2 <- matrix(nrow=26,ncol=11)
matrix2[c(1:3),1] <- 1 #Alexander
matrix2[c(1:3),c(2:11)] <- 0
matrix2[c(5:6),2] <- 1 #Stender
matrix2[c(5:6),c(1,3:11)] <- 0 
matrix2[c(4,7,10,12),3] <- 1 #Seiad Creek
matrix2[c(4,7,10,12),c(1,2,4:11)] <- 0
matrix2[8,4] <- 1 #Durazo
matrix2[8,c(1:3,5:11)] <- 0
matrix2[9,5] <- 1 #Lower Seiad
matrix2[9,c(1:4,6:11)] <- 0
matrix2[11,6] <- 1 #May
matrix2[11,c(1:5,7:11)] <- 0
matrix2[c(13:14),7] <- 1 #Fish Gulch
matrix2[c(13:14),c(1:6,8:11)] <- 0
matrix2[c(16:18),8] <- 1 #Goodman
matrix2[c(16:18),c(1:7,9:11)] <- 0
matrix2[c(20:22),9] <- 1 #Upper Lawrence
matrix2[c(20:22),c(1:8,10:11)] <- 0
matrix2[c(24:26),10] <- 1 #Lower Lawrence
matrix2[c(24:26),c(1:9,11)] <- 0
matrix2[c(15,19,23),11] <- 1 #Horse Creek
matrix2[c(15,19,23),c(1:10)] <- 0

#Hypothesis 2: ponds versus creeks
matrix3 <- matrix(nrow=26, ncol=2)
matrix3[c(1:3,5:6,8:9,11,13:14,16:18,20:22,24:26),1] <- 1 #All ponds
matrix3[c(1:3,5:6,8:9,11,13:14,16:18,20:22,24:26),2] <- 0
matrix3[c(4,7,10,12,15,19,23),1] <- 0 #All creeks
matrix3[c(4,7,10,12,15,19,23),2] <- 1

#Hypothesis 3: tributary versus tributary
matrix4 <-matrix(nrow=26,ncol=4)
matrix4[c(1:3,5:6,8:9,11),1] <- 1  #Seiad Creek Ponds
matrix4[c(1:3,5:6,8:9,11),c(2:4)] <- 0
matrix4[c(4,7,10,12),2] <- 1 #Seiad Creek
matrix4[c(4,7,10,12),c(1,3:4)] <- 0
matrix4[c(13:14,16:18,20:22,24:26),3] <- 1 #Horse Creek Ponds
matrix4[c(13:14,16:18,20:22,24:26),c(1,2,4)] <- 0
matrix4[c(15,19,23),4] <- 1 #Horse Creek
matrix4[c(15,19,23),c(1:3)] <- 0

#Hypothesis 4: All sensors are the same
matrix5 <-  matrix(nrow=26, ncol=1)
matrix5[,] <- 1

```

##Covariates
```{r, include=FALSE}
airtemp <- read.csv("SlaterButteAirTemp_2020_2021.csv")
str(airtemp)
plot(airtemp$TAVG)

#Need to convert F to C, but can only perform this function once per download of the dataset becuase it'll do it again
airtemp$TAVG <- fahrenheit.to.celsius(airtemp$TAVG)
airtemp$TMAX <- fahrenheit.to.celsius(airtemp$TMAX)
airtemp$TMIN <- fahrenheit.to.celsius(airtemp$TMIN)

airtemp$date <- lubridate::mdy(airtemp$DATE)
missing_data <- airtemp[!complete.cases(airtemp),] #No missing data
missing_data
airtemp$day <- lubridate::floor_date(airtemp$date, unit="day")
str(airtemp)
#cut to fit our data (1 July 2020 through 13 July 2021)
airtemp <- airtemp[c(1:381),]
str(airtemp)
head(airtemp)
tail(airtemp,30)

#Can't figure out if there is a shift-- last year I had a 4 day shift but now can't really tell. Will run with 4 day shift agan for fun. 
#so I need to shift covariate data to the RIGHT by 4 days
#cut to fit our data (4 July 2020 through 17 July 2021)
airtemp <- airtemp[c(4:381),]
str(airtemp)
#Convert to time series
airtempts <- ts(airtemp$TAVG, start = c(4, 1), frequency = 1) #The sensor records 1 reading per day. This time series starts on July 4 
ts.plot(airtempts,main="Temperature",ylab = "Temperature (C)", xlab = "Day") 

#Build the little c matrix, call it matrixc
matrixc <- matrix(nrow=1,ncol=378)
matrixc <- t(as.matrix(airtemp$TAVG))
matrixc

```


##MARSS models with Covariates and Mean temps
```{r }
#Hypothesis 1, Model 1: All ponds and creeks are separate
mod1 = list()
mod1$A = "zero" #no trend because we z scored
mod1$Z = matrix2
mod1$R = "diagonal and equal" #all the sensors are the same type, so observation error should be the same
mod1$Q = "unconstrained" #leave Q unconstrained because we expect some covariance between sensors (also try Equalvarcov)
mod1$B = "identity" #assuming no species interactions
mod1$U = "zero" #no trend because we z scored 
mod1$C = "unequal" #I think I can set C to unequal because it is going off the Z matrix where I have already indicated how to split up the sites.
mod1$c = matrixc
mod1.fit = MARSS(transformed_dat, model=mod1, control=list(maxit=10000))
MARSSparamCIs(mod1.fit)
#AICc is -435.1345                  

#Hypothesis 2, Model 3: ponds vs. creeks 
mod2 <- mod1 
mod2$Z <- matrix3
mod2.fit = MARSS(transformed_dat, model=mod2, control=list(maxit=10000))
MARSSparamCIs(mod2.fit)
#AICc is 9942.797              

#Hypothesis 3, Model 3: Tributary versus tributary
mod3 <- mod1
mod3$Z = matrix4
mod3.fit = MARSS(transformed_dat, model=mod3, control=list(maxit=10000))
MARSSparamCIs(mod3.fit)
#AICc is 3533.516                       

#Hypothesis 4, Model 4: All same
mod4 <- mod1 
mod4$Z <- matrix5
mod4.fit = MARSS(transformed_dat, model=mod4, control=list(maxit=10000))
MARSSparamCIs(mod4.fit)
#AICc is 10262.35   

```
